캐글1 새롭게 배운 것

df_train['Initial'] = df_train.Name.str.extract('([A-Za-z]+)\.')

pd의 replace로 데이터 값 바꾸기

pd의 fillna로 결측치 대체하기

all()의 용도

map으로 범주형 변수 수치형으로 바꾸기

any()의 용도

sns.heatmap으로 상관계수 시각화

one-hot encoding with pd.get_dummies()

sort_values()로 Series 정렬
------------------------------------------------------------------------------------------

캐글2 새롭게 배운 것

plt.gcf() : 현재 figure에 접근하고자 할 때
plt.subplots_adjust(wspace=0.2, hspace=0.5) : 서브플랏들 간의 간격을 조정하고자 할 때
pd.qcut :  지정해준 bin 개수만큼 연속형 변수를 나누어서 범주형으로 만들어준다.
to_frame() : 배열을 데이터프레임으로 변환해준다.
from sklearn.model_selection import KFold, cross_val_score, cross_val_predict : 트레이닝/ 테스트 데이터가 바뀌면 정확도가 떨어질 수 있다. model variance -> Kfold

GridSearchCV가 데이터를 자동적으로 나누어 주기 때문에 train&validation set으로 나누어 fit할 필요가 없다.

----------------------------------
캐글3 새롭게 배운 것

sns 그래프, x ,y값 각각 할당해주면 data를 지정한다.(barplot, catplot...)
distplot같은 data['col1'] 같이 지정하는 그래프는 data지정 X

tukey method로 이상치 탐지하기
- np.percentile(data, 25) -> 데이터에서 하위 25% 값을 반환

collections.Counter - 리스트 원소 개수 세서 원소(키) : 개수(밸류) 딕셔너리로 반환
- Counter.update() : 카운터로 구한 기존 딕셔너리에 업데이트

sns.despine(방향=True) : 축을 삭제한다.

FacetGrid로 원하는 컬럼 별로 데이터 살펴보기
<- 기존에는 f, ax = plt.subplots(1, 2, figsize=(12,8)) 과 같이 길게 씀.

np.isnan(data) - data(array)가 NaN인지 확인

pd.isnull(data) - Series데이터가 null인지 확인

plt.setp로 피규어 선 모양 다루기

isdigit() - '문자열'이 숫자인지 문자인지 확인한다.
**{'xerr':cv_std}) - 그래프에 에러바를 추가한다. **은 키워드 인자.

learning_curve로 학습곡선을 그려보자. (학습 데이터와 정확도에 관한 그래프)
- train_sizes
- train_scores
- test_scores
를 리턴한다. 추가적으로 학습 시간도 반환하지만 따로 설정해야 한다.

np.argsort - 작은 값부터 순서대로 데이터의 인덱스를 반환한다.
-----
- 범주형 모두 더미변수로?
- **{} 빼도 잘 작동...?

- CV에서 왜 그것들 선택했는지?
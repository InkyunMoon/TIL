# Auto Encoder

>**오토 인코더는 출력이 입력 데이터와 같아지도록 학습한 네트워크이다.**
>
>**(1) 차원축소 (2) 잡음제거 (3) 이상 데이터 검출 (4) 사전학습 등에 활용될 수 있다.**

### (1) 차원 축소

#### 1. 784차원의 feature로 구성된 mnist 데이터 100개의 차원으로 축소 (예제 7-1)

표준화된 인풋데이터 inputX가 있다고 하자. 계산상의 편의를 위해 3000개의 데이터만 사용한다.

```python
inputX.shape
> (3000, 784)

# 모델을 생성한다.
xInput = Input(batch_shape=(None, nInput))
xEncoder = Dense(256, activation='relu')(xInput)
xEncoder = Dense(nFeature, activation='relu')(xEncoder)
yDecoder = Dense(256, activation='relu')(xEncoder)
yDecoder = Dense(nOutput, activation='linear')(yDecoder)
model = Model(xInput, yDecoder)
encoder = Model(xInput, xEncoder)
model.compile(loss='mse', optimizer=Adam(lr=0.01))

# autoencoder를 학습한다
hist = model.fit(inputX, inputX, epochs=500, batch_size=100)
# 학습된 autoencoder를 이용하여 입력 데이터의 차원을 축소한다.
inputXE = encoder.predict(inputX)

inputXE.shape
> (3000, 100)
# 784차원을 100차원으로 축소하였다. 

model.summary()
>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 784)]             0         
_________________________________________________________________
dense (Dense)                (None, 256)               200960    
_________________________________________________________________
dense_1 (Dense)              (None, 100)               25700     
_________________________________________________________________
dense_2 (Dense)              (None, 256)               25856     
_________________________________________________________________
dense_3 (Dense)              (None, 784)               201488    
=================================================================
Total params: 454,004
Trainable params: 454,004
Non-trainable params: 0
```



#### 2. CNN을 이용하여 mnist데이터에 추가된 잡음 제거(예제 7-2)

Convolution2D를 사용할 것이므로, 입력되는 데이터의 차원은 (batch, height, width, channel)의 4차원으로 구성되어야 한다.

```python
inputX=inputX.reshape(-1, 28, 28)

# CNN AutoEncoder.
nHeight = inputX.shape[1]
nWidth = inputX.shape[2]
xInput = Input(batch_shape=(None, nHeight, nWidth, 1))

# encoder
# (28, 28) 이미지를 (14, 14) 이미지로 줄인다.
eConv = Conv2D(filters=10, kernel_size=(5,5), strides=2, padding = 'same', activation='relu')(xInput)
ePool = MaxPooling2D(pool_size=(5,5), strides=1, padding='valid')(eConv)
eFlat = Flatten()(ePool)
eLatent = Dense(14 * 14, activation='linear')(eFlat) # (28, 28) --> (14, 14)로 축소
eLatent = Reshape((14, 14, 1))(eLatent)

# decoder
# 이미지를 strides = 2 배 만큼 늘린다. 결과 = (20, 8) : 원본 이미지
dConv = Conv2DTranspose(filters=10, kernel_size=(4,4), strides=2, padding = 'same', activation='relu')(eLatent)
xOutput = Conv2D(1, kernel_size=(4,4), strides=1, padding = 'same')(dConv)

model = Model(xInput, xOutput)
model.compile(loss='mse', optimizer=Adam(lr=0.005))
encoder = Model(xInput, eLatent)

# AE를 학습한다.
inputX = inputX[:, :, :, np.newaxis]      # channel 축을 추가한다.
h = model.fit(inputX, inputX, epochs = 100, batch_size=300, shuffle=True)

model.summary()
>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 14, 14, 10)        260       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 10, 10, 10)        0         
_________________________________________________________________
flatten (Flatten)            (None, 1000)              0         
_________________________________________________________________
dense_14 (Dense)             (None, 196)               196196    
_________________________________________________________________
reshape (Reshape)            (None, 14, 14, 1)         0         
_________________________________________________________________
conv2d_transpose (Conv2DTran (None, 28, 28, 10)        170       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 28, 1)         161       
=================================================================
Total params: 196,787
Trainable params: 196,787
Non-trainable params: 0
```



#### 3. LSTM을 이용하여 차원 축소(예제 7-3)

```python
xInput = Input(batch_shape=(None, inputX.shape[1], inputX.shape[2]))

#encoder(28개의 피쳐 -> 8개의 피쳐로 차원 축소)
eLstm = Bidirectional(LSTM(nFeature, return_sequences=True), merge_mode = 'sum')(xInput)
# LSTM는 3차원으로 입력을 받아 2차원으로 출력하는 구조이지만, return_sequences = True 옵션을 통해 3차원입력 -> 3차원 출력을 유지할 수 있다.

#decoder
dLstm = Bidirectional(LSTM(nFeature, return_sequences=True), merge_mode = 'sum')(eLstm)
xOutput = TimeDistributed(Dense(inputX.shape[2]))(dLstm)

model = Model(xInput, xOutput)
model.compile(loss='mse', optimizer=Adam(lr=0.001))
encoder = Model(xInput, eLstm)

# AE를 학습한다.
h = model.fit(inputX, inputX, epochs = 500, batch_size=300, shuffle=True)

model.summary()
>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 28, 28)]          0         
_________________________________________________________________
bidirectional_8 (Bidirection (None, 28, 8)             2368      
_________________________________________________________________
bidirectional_9 (Bidirection (None, 28, 8)             1088      
_________________________________________________________________
time_distributed_1 (TimeDist (None, 28, 28)            252       
=================================================================
Total params: 3,708
Trainable params: 3,708
Non-trainable params: 0
```



### (2) 잡음 제거

np.random.nomral(loc=분포의 평균,scale=분포의 표준편차,size=생성할 난수 사이즈)

```python
trainX = mnist.data[:3000, :] / 255
testX = mnist.data[3000:3100, :] / 255

# 학습 데이터와 시험 데이터에 노이즈를 삽입한다.
trainXN = trainX + 0.3 * np.random.normal(loc=0.0, scale=1.0, size=trainX.shape)
testXN = testX + 0.3 * np.random.normal(loc=0.0, scale=1.0, size=testX.shape)
trainXN = np.clip(trainXN, 0., 1.)
testXN = np.clip(testXN, 0., 1.)

# CNN AutoEncoder.
trainX = trainX.reshape(-1, 28, 28)
trainXN = trainXN.reshape(-1, 28, 28)
nHeight = trainXN.shape[1]
nWidth = trainXN.shape[2]
xInput = Input(batch_shape=(None, nHeight, nWidth, 1))

# encoder
eConv = Conv2D(filters=10, kernel_size=(3,3), strides=1, padding = 'same', activation='relu')(xInput)
ePool = MaxPooling2D(pool_size=(2,2), strides=1, padding='same')(eConv)

# decoder
dConv = Conv2DTranspose(filters=10, kernel_size=(3,3), strides=1, padding = 'same', activation='relu')(ePool)
xOutput = Conv2D(1, kernel_size=(3,3), strides=1, padding = 'same', activation='sigmoid')(dConv)

model = Model(xInput, xOutput)
model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.005))

# AE를 학습한다.
trainXN = trainXN[:, :, :, np.newaxis]      # channel 축을 추가한다.
h = model.fit(trainXN, trainX, epochs = 100, batch_size=300, shuffle=True)

model.summary()
>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 28, 28, 10)        100       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 28, 28, 10)        0         
_________________________________________________________________
conv2d_transpose (Conv2DTran (None, 28, 28, 10)        910       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 28, 1)         91        
=================================================================
Total params: 1,101
Trainable params: 1,101
Non-trainable params: 0
```





### (3) 이상 데이터 검출
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7a8f585ed58b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m# -----\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoderX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoderX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# Chatting용 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[0;32m    248\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[0;32m    249\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m   def compile(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[0;32m   1257\u001b[0m           'first, then load the weights.')\n\u001b[0;32m   1258\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Seq2Seq를 이용한 ChatBot : 채팅 모듈\n",
    "# 참고한 자료 :\n",
    "# https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py\n",
    "#\n",
    "# 2020.06.04 : 조성현 (blog.naver.com/chunjein)\n",
    "# ------------------------------------------------------------------------\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pickle\n",
    "# C:/inkyun/실습파일과 교재/5.자연어처리(실습파일)/dataset/\n",
    "# 단어 목록 dict를 읽어온다.\n",
    "with open('./dataset/6-1.vocabulary.pickle', 'rb') as f:\n",
    "    word2idx,  idx2word = pickle.load(f)\n",
    "\n",
    "VOCAB_SIZE = len(idx2word)\n",
    "EMB_SIZE = 128\n",
    "LSTM_HIDDEN = 128\n",
    "MAX_SEQUENCE_LEN = 10            # 단어 시퀀스 길이\n",
    "MODEL_PATH = './dataset/6-2.Seq2Seq.h5'\n",
    "\n",
    "# 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\n",
    "K.clear_session()\n",
    "wordEmbedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)\n",
    "\n",
    "# Encoder\n",
    "# -------\n",
    "encoderX = Input(batch_shape=(None, MAX_SEQUENCE_LEN))\n",
    "encEMB = wordEmbedding(encoderX)\n",
    "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
    "encLSTM2 = LSTM(LSTM_HIDDEN, return_state = True)\n",
    "ey1, eh1, ec1 = encLSTM1(encEMB)    # LSTM 1층 \n",
    "_, eh2, ec2 = encLSTM2(ey1)         # LSTM 2층\n",
    "\n",
    "# Decoder\n",
    "# -------\n",
    "# Decoder는 1개 단어씩을 입력으로 받는다. 학습 때와 달리 문장 전체를 받아\n",
    "# recurrent하는 것이 아니라, 단어 1개씩 입력 받아서 다음 예상 단어를 확인한다.\n",
    "# chatting()에서 for 문으로 단어 별로 recurrent 시킨다.\n",
    "# 따라서 batch_shape = (None, 1)이다. 즉, time_step = 1이다. 그래도 네트워크\n",
    "# 파라메터는 동일하다.\n",
    "decoderX = Input(batch_shape=(None, 1))\n",
    "decEMB = wordEmbedding(decoderX)\n",
    "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
    "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
    "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
    "outputY = decOutput(dy2)\n",
    "\n",
    "# Model\n",
    "# -----\n",
    "model = Model([encoderX, decoderX], outputY)\n",
    "model.load_weights(MODEL_PATH)\n",
    "\n",
    "# Chatting용 model\n",
    "model_enc = Model(encoderX, [eh1, ec1, eh2, ec2])\n",
    "\n",
    "ih1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ih2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "\n",
    "dec_output1, dh1, dc1 = decLSTM1(decEMB, initial_state = [ih1, ic1])\n",
    "dec_output2, dh2, dc2 = decLSTM2(dec_output1, initial_state = [ih2, ic2])\n",
    "\n",
    "dec_output = decOutput(dec_output2)\n",
    "model_dec = Model([decoderX, ih1, ic1, ih2, ic2], \n",
    "                  [dec_output, dh1, dc1, dh2, dc2])\n",
    "\n",
    "# Question을 입력받아 Answer를 생성한다.\n",
    "def genAnswer(question):\n",
    "    question = question[np.newaxis, :]\n",
    "    init_h1, init_c1, init_h2, init_c2 = model_enc.predict(question)\n",
    "\n",
    "    # 시작 단어는 <START>로 한다.\n",
    "    word = np.array(word2idx['<START>']).reshape(1, 1)\n",
    "\n",
    "    answer = []\n",
    "    for i in range(MAX_SEQUENCE_LEN):\n",
    "        dY, next_h1, next_c1, next_h2, next_c2 = \\\n",
    "            model_dec.predict([word, init_h1, init_c1, init_h2, init_c2])\n",
    "        \n",
    "        # 디코더의 출력은 vocabulary에 대응되는 one-hot이다.\n",
    "        # argmax로 해당 단어를 채택한다.\n",
    "        nextWord = np.argmax(dY[0, 0])\n",
    "        \n",
    "        # 예상 단어가 <END>이거나 <PADDING>이면 더 이상 예상할 게 없다.\n",
    "        if nextWord == word2idx['<END>'] or nextWord == word2idx['<PADDING>']:\n",
    "            break\n",
    "        \n",
    "        # 다음 예상 단어인 디코더의 출력을 answer에 추가한다.\n",
    "        answer.append(idx2word[nextWord])\n",
    "        \n",
    "        # 디코더의 다음 recurrent를 위해 입력 데이터와 hidden 값을\n",
    "        # 준비한다. 입력은 word이고, hidden은 h와 c이다.\n",
    "        word = np.array(nextWord).reshape(1,1)\n",
    "    \n",
    "        init_h1 = next_h1\n",
    "        init_c1 = next_c1\n",
    "        init_h2 = next_h2\n",
    "        init_c2 = next_c2\n",
    "        \n",
    "    return ' '.join(answer)\n",
    "\n",
    "# Chatting\n",
    "def chatting(n=100):\n",
    "    for i in range(n):\n",
    "        question = input('Q : ')\n",
    "        \n",
    "        if  question == 'quit':\n",
    "            break\n",
    "        \n",
    "        q_idx = []\n",
    "        for x in question.split(' '):\n",
    "            if x in word2idx:\n",
    "                q_idx.append(word2idx[x])\n",
    "            else:\n",
    "                q_idx.append(word2idx['<UNKNOWN>'])   # out-of-vocabulary (OOV)\n",
    "        \n",
    "        # <PADDING>을 삽입한다.\n",
    "        if len(q_idx) < MAX_SEQUENCE_LEN:\n",
    "            q_idx.extend([word2idx['<PADDING>']] * (MAX_SEQUENCE_LEN - len(q_idx)))\n",
    "        else:\n",
    "            q_idx = q_idx[0:MAX_SEQUENCE_LEN]\n",
    "        \n",
    "        answer = genAnswer(np.array(q_idx))\n",
    "        print('A :', answer)\n",
    "\n",
    "chatting(100)\n",
    "\n",
    "# 대화 내용 예시\n",
    "# 가끔 궁금해 : 그 사람도 그럴 거예요.,0\n",
    "# 가끔 뭐하는지 궁금해 : 그 사람도 그럴 거예요.,0\n",
    "# 가끔은 혼자인게 좋다 : 혼자를 즐기세요.,0\n",
    "# 가난한 자의 설움 : 돈은 다시 들어올 거예요.,0\n",
    "# 가만 있어도 땀난다 : 땀을 식혀주세요.,0\n",
    "# 가상화폐 쫄딱 망함 : 어서 잊고 새출발 하세요.,0\n",
    "# 가스불 켜고 나갔어 : 빨리 집에 돌아가서 끄고 나오세요.,0\n",
    "# 가스불 켜놓고 나온거 같아 : 빨리 집에 돌아가서 끄고 나오세요.,0\n",
    "# 가스비 너무 많이 나왔다. : 다음 달에는 더 절약해봐요.,0\n",
    "# 가스비 비싼데 감기 걸리겠어 : 따뜻하게 사세요!,0\n",
    "# 남자친구 교회 데려가고 싶어 : 마음을 열 때까지 설득해보세요.,0\n",
    "# 남자친구 또 운동 갔어 : 운동을 함께 해보세요.,0\n",
    "# 남자친구 생일인데 뭘 줄까 : 평소에 필요한 것 생각해보세요.,0\n",
    "# 남자친구 승진 선물로 뭐가 좋을까? : 평소에 필요했던 게 좋을 것 같아요.,0\n",
    "# 남자친구 오늘 따라 훈훈해 보인다 : 전생에 나라를 구하셨나요.,0\n",
    "# 남자친구 오늘 좀 질린다. : 결단은 빠를수록 좋아요.,0\n",
    "# 남자친구가 나 안 믿어줘 : 거짓말 적당히 하세요.,0\n",
    "# 남자친구가 너무 바빠 : 너무 집착하지 마세요.,0\n",
    "# 남자친구가 너무 운동만 해 : 운동을 함께 해보세요.,0\n",
    "# 남자친구가 너무 잘생겼어 : 전생에 나라를 구하셨나요.,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

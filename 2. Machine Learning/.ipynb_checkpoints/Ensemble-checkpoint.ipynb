{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블\n",
    "- 단일 알고리즘을 사용하는 것보다 여러 알고리즘을 사용한 후 결과를 종합하는 것이 더 좋다.\n",
    "    - 정확도와 일반화 특성 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부스팅\n",
    "> 분류가 어려운 패턴에 더욱 집중하여 정확도를 높이는 방법\n",
    "\n",
    "- 서브 훈련 데이터 샘플을 만든다.\n",
    "- 첫 샘플링은 모든 데이터에 동일 가중치를 두어 샘플링한다.\n",
    "- 처음 샘플링된 데이터로 학습한다.\n",
    "- 분류가 잘못된 데이터의 가중치를 높이고 다시 샘플링한다.\n",
    "    - 잘못 분류된 패턴은 선택될 확률이 높아진다.\n",
    "- 새로운 샘플링으로 다시 학습한다.\n",
    "- 이를 반복하여 점차 분류하기 어려운 패턴들을 많이 선택하여 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost (Adaptive Boosting)\n",
    "AdaBoost는 Decision Trees와 합쳐서 설명하는 것이 일반적이라고 한다.\n",
    "\n",
    "AdaBoost는 하나의 노드에 두개의 잎으로 구성되어있다. 하나의 노드와 두개의 잎으로 구성된 트리를 스텀프라고 한다.\n",
    "\n",
    "일반적인 Decision Tree는 데이터의 모든 컬럼을 활용하여 의사결정을 할 수 있는데(컬럼마다 노드를 이용하여 구분한다), 스텀프는 하나의 컬럼밖에 사용할 수 없으므로 **weak learner(약한 분류기)**라고 불린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

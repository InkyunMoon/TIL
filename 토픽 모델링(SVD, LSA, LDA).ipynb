{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[딥 러닝을 이용한 자연어 처리 입문(바로가기)](https://wikidocs.net/30707)을 정리한 내용입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토픽 모델링\n",
    "- **문서 집합의 추상적인 주제를 발견**하기 위한 모델링\n",
    "- 텍스트 본문의 숨겨진 의미 구조를 발견하기 위해 사용되는 텍스트 마이닝 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA개요\n",
    "- TF-IDF와 같은 빈도수 기반 표현방법은 단어의 의미를 고려하지 못한다.\n",
    "- 따라서, 잠재된(Latent)의미를 이끌어내는 방법으로 LSA가 사용되었다.(SVD에 대한 이해 필요)\n",
    "- 즉, DTM이나 TF-IDF행렬에 truncated SVD를 사용해서 차원을 축소, 잠재적 의미를 이끌어낸다는 아이디어\n",
    "\n",
    "\n",
    "## 1) 일반적 SVD(Full SVD)\n",
    "- m * n 행렬 A를 다음과 같이 분해하는 것.\n",
    "$$A = UΣV^T$$\n",
    "\n",
    "$$U: m x m 직교행렬(AA^T = U(ΣΣ^T)U^T)$$\n",
    "$$V: n x n 직교행렬(A^TA = V(Σ^TΣ)V^T)$$\n",
    "$$Σ: m x n 직사각  대각행렬$$\n",
    "- 행렬Σ의 주대각원소를 행렬 A의 특이값이라고 하며, 내림차순으로 정렬되어있다.\n",
    "\n",
    "## 2) Truncated SVD\n",
    "- LSA의 경우 SVD에서 나온 행렬들을 일부 삭제하여 사용한다.\n",
    "     - 설명력이 낮은 정보 삭제 -> 계산비용 낮춤\n",
    "- Σ의 대각원소의 값 중 상위 t개의 값만 남긴다.\n",
    "    - t는 찾고자 하는 토픽의 수\n",
    "    - 크게잡으면 다양한 의미 가져갈 수 있지만 노이즈 존재\n",
    "- 절단시키면 값의 손실이 일어나 A행렬로 복원할 수 없다.\n",
    "\n",
    "\n",
    "Σ에서 t개의 topics만 선택했다고 해보자.  \n",
    "> U: m x t -> 문서 개수 x 토픽의 수  \n",
    "VT: t x n -> 토픽의 수 x 단어 개수의 크기  \n",
    "Σ : t x t  \n",
    "\n",
    "각 행렬들이 위와 같은 사이즈로 결정될 것이다.\n",
    "\n",
    "- U의 각 행은 잠재 의미를 표현하기 위한 수치화된 각각의 문서 벡터  \n",
    "\n",
    "- VT의 각 열은 잠재 의미를 표현하기 위해 수치화된 각각의 단어 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA 실습(추후에 정리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

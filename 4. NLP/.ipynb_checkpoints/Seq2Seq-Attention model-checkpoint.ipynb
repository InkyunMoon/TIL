{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq-Attention modeling 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 학습 단계\n",
    "### 인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- many-to-many로 구성한다. attention value를 계산하기 위해 중간 출력이 필요하다.\n",
    "    - return_sequcences = True\n",
    "- decoder로 전달할 h와 c도 필요하다.\n",
    "    - return_state = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEmbedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)\n",
    "\n",
    "encoderX = Input(batch_shape=(None, MAX_SEQUENCE_LEN))\n",
    "encEMB = wordEmbedding(encoderX)\n",
    "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
    "encLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
    "ey1, eh1, ec1 = encLSTM1(encEMB)    # LSTM 1층 \n",
    "ey2, eh2, ec2 = encLSTM2(ey1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디코더\n",
    "- many-to-many로 구성한다. 초기 h와 c는 encoder에서 출력한 값을 사용한다.\n",
    "    - initial_state = True\n",
    "- 최종 출력(target)은 vocabulary의 인덱스인 one-hot 인코더이다.\n",
    "    - target이 one-hot 인코딩 되어있으면 loss = categorical_crossentropy\n",
    "    - integer로 되어 있으면 sparse_categorical_crossentropy 사용\n",
    "        - sparse_categorical_crossentropy: integer target을 one-hot으로 변환 후 categorical_entropy를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0dec9a45234b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecoderX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainXD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# teacher-forcing. 디코더의 입력값을 알고 있으므로 한꺼번에 recurrent시킨다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdecEMB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoderX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdecLSTM1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM_HIDDEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdecLSTM2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM_HIDDEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "decoderX = Input(batch_shape=(None, trainXD.shape[1]))\n",
    "# teacher-forcing. 디코더의 입력값을 알고 있으므로 한꺼번에 recurrent시킨다.\n",
    "decEMB = wordEmbedding(decoderX)\n",
    "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
    "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
    "att_dy2 = Attention(ey2, dy2)\n",
    "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
    "outputY = decOutput(att_dy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 테스트 단계(chat)\n",
    "## 인코더\n",
    "- 학습 단계와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 디코더\n",
    "- 한번에 하나의 단어를 입력으로 받아 당므 예상 단어를 예측한다.\n",
    "- 초기 h와 c는 encoder에서 출력한 값을 사용한다.(initial_state=True)\n",
    "- 최종 출력(target)은 vocabulary의 인덱스인 one-hot 인코더이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderX = Input(batch_shape=(None, trainXD.shape[1]))\n",
    "decEMB = wordEmbedding(decoderX)\n",
    "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
    "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
    "att_dy2 = Attention(ey2, dy2) ### *설명 참조\n",
    "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
    "outputY = decOutput(att_dy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Attention 함수에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attention(x, y):\n",
    "    # step-1:\n",
    "    # decoder의 매 시점마다 encoder의 전체 시점과 dot-product을 수행한다.\n",
    "    score = Dot(axes=(2, 2))([y, x])                   # (1, 4, 4)\n",
    "    \n",
    "    # step-2:\n",
    "    # dot-product 결과를 확률분포로 만든다 (softmax)\n",
    "    # 이것이 attention score이다.\n",
    "    dist = Activation('softmax')(score)                # (1, 4, 4)\n",
    "\n",
    "    # step-3:    \n",
    "    # encoder의 전체 시점에 위의 확률 분포를 적용해서 가중 평균한다.\n",
    "    # 직접 계산이 어렵기 때문에 dist를 확장하고, 열을 복제해서\n",
    "    # Dot 연산이 가능하도록 trick을 쓴다.\n",
    "    # 이것이 attention value이다.\n",
    "    # dist_exp = K.expand_dims(dist, 2)                   # (1, 4, 1, 4)\n",
    "    # dist_rep = K.repeat_elements(dist_exp, EMB_SIZE, 2) # (1, 4, 3, 4)                                       \n",
    "    # dist_dot = Dot(axes=(3, 1))([dist_rep, x])          # (1, 4, 3, 3)\n",
    "    # attention = K.mean(dist_dot, axis = 2)              # (1, 4, 3)\n",
    "    ### 현재 모델에서는 step3을 스킵하고 step4를 계산하는 간단한 방법 사용 가능.\n",
    "    \n",
    "    # step-4: \n",
    "    # 교재의 step-3을 계산하지 않고 step-4를 직접 계산했다.\n",
    "    attention = Dot(axes=(2, 1))([dist, x])\n",
    "    \n",
    "    # step-5:\n",
    "    # decoder 출력과 attention을 concatenate 한다.\n",
    "    return Concatenate()([y, attention])    # (1, 4, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image1](https://github.com/InkyunMoon/TIL/blob/master/markdown-images/0812_AttentionScore(계산)-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수학적으로 내적은 2차원 벡터에 대해서만 연산이 가능하지만, python에서 3차원 이상의 데이터에 대해 dot을 수행하면 2차원 데이터들을 내적하여 합하는 형식으로 계산한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

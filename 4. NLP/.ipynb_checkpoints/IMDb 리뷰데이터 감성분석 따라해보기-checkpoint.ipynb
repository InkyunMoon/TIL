{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('C:/Users/moon/Desktop/5.자연어처리(실습파일)/dataset/4-1.labeledTrainData.tsv', header = 0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review, stops, remove_stopwords = True):\n",
    "    review_text = BeautifulSoup(review, 'html5lib').get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    words = [w for w in words if not w in stops]\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    clean_review = ' '.join(words)\n",
    "    return clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "clean_train_reviews = []\n",
    "for review in train_data['review']:\n",
    "    r = preprocessing(review, stops, remove_stopwords = True)\n",
    "    clean_train_reviews.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuff go moment mj start listen music watch odd documentari watch wiz watch moonwalk mayb want get certain insight guy thought realli cool eighti mayb make mind whether guilti innoc moonwalk part biographi part featur film rememb go see cinema origin releas subtl messag mj feel toward press also obviou messag drug bad kay visual impress cours michael jackson unless remot like mj anyway go hate find bore may call mj egotist consent make movi mj fan would say made fan true realli nice actual featur film bit final start minut exclud smooth crimin sequenc joe pesci convinc psychopath power drug lord want mj dead bad beyond mj overheard plan nah joe pesci charact rant want peopl know suppli drug etc dunno mayb hate mj music lot cool thing like mj turn car robot whole speed demon sequenc also director must patienc saint came film kiddi bad sequenc usual director hate work one kid let alon whole bunch perform complex danc scene bottom line movi peopl like mj one level anoth think peopl stay away tri give wholesom messag iron mj bestest buddi movi girl michael jackson truli one talent peopl ever grace planet guilti well attent gave subject hmmm well know peopl differ behind close door know fact either extrem nice stupid guy one sickest liar hope latter'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df = pd.DataFrame({'review': clean_train_reviews,'sentiment':train_data['sentiment']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df.to_csv('C:/Users/moon/Desktop/5.자연어처리(실습파일)/saved_data/1.train_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('C:/Users/moon/Desktop/5.자연어처리(실습파일)/saved_data/1.train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(train_data['review'])\n",
    "sentiments = np.array(list(train_data['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "text_sequences = tokenizer.texts_to_sequences(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_label = []\n",
    "for review, label in zip(text_sequences, sentiments):\n",
    "    for w in review:\n",
    "        words_label.append([w,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_label = np.array(word_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-a42271a5ff20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# p(y=0)과 p(y=1)을 계산해 둔다. py[0] = p(y=0), py[1] = p(y=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-a42271a5ff20>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# p(y=0)과 p(y=1)을 계산해 둔다. py[0] = p(y=0), py[1] = p(y=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "x = np.array([np.where(word_label[:, 1] == i)[0] for i in [0, 1]])\n",
    "\n",
    "# p(y=0)과 p(y=1)을 계산해 둔다. py[0] = p(y=0), py[1] = p(y=1)\n",
    "py = np.array([(word_label[:, 1] == i).mean() for i in [0, 1]])\n",
    "N = len(idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 / 50597\n",
      "200 / 50597\n",
      "300 / 50597\n",
      "400 / 50597\n",
      "500 / 50597\n",
      "600 / 50597\n",
      "700 / 50597\n",
      "800 / 50597\n",
      "900 / 50597\n",
      "1000 / 50597\n",
      "1100 / 50597\n",
      "1200 / 50597\n",
      "1300 / 50597\n",
      "1400 / 50597\n",
      "1500 / 50597\n",
      "1600 / 50597\n",
      "1700 / 50597\n",
      "1800 / 50597\n",
      "1900 / 50597\n",
      "2000 / 50597\n",
      "2100 / 50597\n",
      "2200 / 50597\n",
      "2300 / 50597\n",
      "2400 / 50597\n",
      "2500 / 50597\n",
      "2600 / 50597\n",
      "2700 / 50597\n",
      "2800 / 50597\n",
      "2900 / 50597\n",
      "3000 / 50597\n",
      "3100 / 50597\n",
      "3200 / 50597\n",
      "3300 / 50597\n",
      "3400 / 50597\n",
      "3500 / 50597\n",
      "3600 / 50597\n",
      "3700 / 50597\n",
      "3800 / 50597\n",
      "3900 / 50597\n",
      "4000 / 50597\n",
      "4100 / 50597\n",
      "4200 / 50597\n",
      "4300 / 50597\n",
      "4400 / 50597\n",
      "4500 / 50597\n",
      "4600 / 50597\n",
      "4700 / 50597\n",
      "4800 / 50597\n",
      "4900 / 50597\n",
      "5000 / 50597\n",
      "5100 / 50597\n",
      "5200 / 50597\n",
      "5300 / 50597\n",
      "5400 / 50597\n",
      "5500 / 50597\n",
      "5600 / 50597\n",
      "5700 / 50597\n",
      "5800 / 50597\n",
      "5900 / 50597\n",
      "6000 / 50597\n",
      "6100 / 50597\n",
      "6200 / 50597\n",
      "6300 / 50597\n",
      "6400 / 50597\n",
      "6500 / 50597\n",
      "6600 / 50597\n",
      "6700 / 50597\n",
      "6800 / 50597\n",
      "6900 / 50597\n",
      "7000 / 50597\n",
      "7100 / 50597\n",
      "7200 / 50597\n",
      "7300 / 50597\n",
      "7400 / 50597\n",
      "7500 / 50597\n",
      "7600 / 50597\n",
      "7700 / 50597\n",
      "7800 / 50597\n",
      "7900 / 50597\n",
      "8000 / 50597\n",
      "8100 / 50597\n",
      "8200 / 50597\n",
      "8300 / 50597\n",
      "8400 / 50597\n",
      "8500 / 50597\n",
      "8600 / 50597\n",
      "8700 / 50597\n",
      "8800 / 50597\n",
      "8900 / 50597\n",
      "9000 / 50597\n",
      "9100 / 50597\n",
      "9200 / 50597\n",
      "9300 / 50597\n",
      "9400 / 50597\n",
      "9500 / 50597\n",
      "9600 / 50597\n",
      "9700 / 50597\n",
      "9800 / 50597\n",
      "9900 / 50597\n",
      "10000 / 50597\n",
      "10100 / 50597\n",
      "10200 / 50597\n",
      "10300 / 50597\n",
      "10400 / 50597\n",
      "10500 / 50597\n",
      "10600 / 50597\n",
      "10700 / 50597\n",
      "10800 / 50597\n",
      "10900 / 50597\n",
      "11000 / 50597\n",
      "11100 / 50597\n",
      "11200 / 50597\n",
      "11300 / 50597\n",
      "11400 / 50597\n",
      "11500 / 50597\n",
      "11600 / 50597\n",
      "11700 / 50597\n",
      "11800 / 50597\n",
      "11900 / 50597\n",
      "12000 / 50597\n",
      "12100 / 50597\n",
      "12200 / 50597\n",
      "12300 / 50597\n",
      "12400 / 50597\n",
      "12500 / 50597\n",
      "12600 / 50597\n",
      "12700 / 50597\n",
      "12800 / 50597\n",
      "12900 / 50597\n",
      "13000 / 50597\n",
      "13100 / 50597\n",
      "13200 / 50597\n",
      "13300 / 50597\n",
      "13400 / 50597\n",
      "13500 / 50597\n",
      "13600 / 50597\n",
      "13700 / 50597\n",
      "13800 / 50597\n",
      "13900 / 50597\n",
      "14000 / 50597\n",
      "14100 / 50597\n",
      "14200 / 50597\n",
      "14300 / 50597\n",
      "14400 / 50597\n",
      "14500 / 50597\n",
      "14600 / 50597\n",
      "14700 / 50597\n",
      "14800 / 50597\n",
      "14900 / 50597\n",
      "15000 / 50597\n",
      "15100 / 50597\n",
      "15200 / 50597\n",
      "15300 / 50597\n",
      "15400 / 50597\n",
      "15500 / 50597\n",
      "15600 / 50597\n",
      "15700 / 50597\n",
      "15800 / 50597\n",
      "15900 / 50597\n",
      "16000 / 50597\n",
      "16100 / 50597\n",
      "16200 / 50597\n",
      "16300 / 50597\n",
      "16400 / 50597\n",
      "16500 / 50597\n",
      "16600 / 50597\n",
      "16700 / 50597\n",
      "16800 / 50597\n",
      "16900 / 50597\n",
      "17000 / 50597\n",
      "17100 / 50597\n",
      "17200 / 50597\n",
      "17300 / 50597\n",
      "17400 / 50597\n",
      "17500 / 50597\n",
      "17600 / 50597\n",
      "17700 / 50597\n",
      "17800 / 50597\n",
      "17900 / 50597\n",
      "18000 / 50597\n",
      "18100 / 50597\n",
      "18200 / 50597\n",
      "18300 / 50597\n",
      "18400 / 50597\n",
      "18500 / 50597\n",
      "18600 / 50597\n",
      "18700 / 50597\n",
      "18800 / 50597\n",
      "18900 / 50597\n",
      "19000 / 50597\n",
      "19100 / 50597\n",
      "19200 / 50597\n",
      "19300 / 50597\n",
      "19400 / 50597\n",
      "19500 / 50597\n",
      "19600 / 50597\n",
      "19700 / 50597\n",
      "19800 / 50597\n",
      "19900 / 50597\n",
      "20000 / 50597\n",
      "20100 / 50597\n",
      "20200 / 50597\n",
      "20300 / 50597\n",
      "20400 / 50597\n",
      "20500 / 50597\n",
      "20600 / 50597\n",
      "20700 / 50597\n",
      "20800 / 50597\n",
      "20900 / 50597\n",
      "21000 / 50597\n",
      "21100 / 50597\n",
      "21200 / 50597\n",
      "21300 / 50597\n",
      "21400 / 50597\n",
      "21500 / 50597\n",
      "21600 / 50597\n",
      "21700 / 50597\n",
      "21800 / 50597\n",
      "21900 / 50597\n",
      "22000 / 50597\n",
      "22100 / 50597\n",
      "22200 / 50597\n",
      "22300 / 50597\n",
      "22400 / 50597\n",
      "22500 / 50597\n",
      "22600 / 50597\n",
      "22700 / 50597\n",
      "22800 / 50597\n",
      "22900 / 50597\n",
      "23000 / 50597\n",
      "23100 / 50597\n",
      "23200 / 50597\n",
      "23300 / 50597\n",
      "23400 / 50597\n",
      "23500 / 50597\n",
      "23600 / 50597\n",
      "23700 / 50597\n",
      "23800 / 50597\n",
      "23900 / 50597\n",
      "24000 / 50597\n",
      "24100 / 50597\n",
      "24200 / 50597\n",
      "24300 / 50597\n",
      "24400 / 50597\n",
      "24500 / 50597\n",
      "24600 / 50597\n",
      "24700 / 50597\n",
      "24800 / 50597\n",
      "24900 / 50597\n",
      "25000 / 50597\n",
      "25100 / 50597\n",
      "25200 / 50597\n",
      "25300 / 50597\n",
      "25400 / 50597\n",
      "25500 / 50597\n",
      "25600 / 50597\n",
      "25700 / 50597\n",
      "25800 / 50597\n",
      "25900 / 50597\n",
      "26000 / 50597\n",
      "26100 / 50597\n",
      "26200 / 50597\n",
      "26300 / 50597\n",
      "26400 / 50597\n",
      "26500 / 50597\n",
      "26600 / 50597\n",
      "26700 / 50597\n",
      "26800 / 50597\n",
      "26900 / 50597\n",
      "27000 / 50597\n",
      "27100 / 50597\n",
      "27200 / 50597\n",
      "27300 / 50597\n",
      "27400 / 50597\n",
      "27500 / 50597\n",
      "27600 / 50597\n",
      "27700 / 50597\n",
      "27800 / 50597\n",
      "27900 / 50597\n",
      "28000 / 50597\n",
      "28100 / 50597\n",
      "28200 / 50597\n",
      "28300 / 50597\n",
      "28400 / 50597\n",
      "28500 / 50597\n",
      "28600 / 50597\n",
      "28700 / 50597\n",
      "28800 / 50597\n",
      "28900 / 50597\n",
      "29000 / 50597\n",
      "29100 / 50597\n",
      "29200 / 50597\n",
      "29300 / 50597\n",
      "29400 / 50597\n",
      "29500 / 50597\n",
      "29600 / 50597\n",
      "29700 / 50597\n",
      "29800 / 50597\n",
      "29900 / 50597\n",
      "30000 / 50597\n",
      "30100 / 50597\n",
      "30200 / 50597\n",
      "30300 / 50597\n",
      "30400 / 50597\n",
      "30500 / 50597\n",
      "30600 / 50597\n",
      "30700 / 50597\n",
      "30800 / 50597\n",
      "30900 / 50597\n",
      "31000 / 50597\n",
      "31100 / 50597\n",
      "31200 / 50597\n",
      "31300 / 50597\n",
      "31400 / 50597\n",
      "31500 / 50597\n",
      "31600 / 50597\n",
      "31700 / 50597\n",
      "31800 / 50597\n",
      "31900 / 50597\n",
      "32000 / 50597\n",
      "32100 / 50597\n",
      "32200 / 50597\n",
      "32300 / 50597\n",
      "32400 / 50597\n",
      "32500 / 50597\n",
      "32600 / 50597\n",
      "32700 / 50597\n",
      "32800 / 50597\n",
      "32900 / 50597\n",
      "33000 / 50597\n",
      "33100 / 50597\n",
      "33200 / 50597\n",
      "33300 / 50597\n",
      "33400 / 50597\n",
      "33500 / 50597\n",
      "33600 / 50597\n",
      "33700 / 50597\n",
      "33800 / 50597\n",
      "33900 / 50597\n",
      "34000 / 50597\n",
      "34100 / 50597\n",
      "34200 / 50597\n",
      "34300 / 50597\n",
      "34400 / 50597\n",
      "34500 / 50597\n",
      "34600 / 50597\n",
      "34700 / 50597\n",
      "34800 / 50597\n",
      "34900 / 50597\n",
      "35000 / 50597\n",
      "35100 / 50597\n",
      "35200 / 50597\n",
      "35300 / 50597\n",
      "35400 / 50597\n",
      "35500 / 50597\n",
      "35600 / 50597\n",
      "35700 / 50597\n",
      "35800 / 50597\n",
      "35900 / 50597\n",
      "36000 / 50597\n",
      "36100 / 50597\n",
      "36200 / 50597\n",
      "36300 / 50597\n",
      "36400 / 50597\n",
      "36500 / 50597\n",
      "36600 / 50597\n",
      "36700 / 50597\n",
      "36800 / 50597\n",
      "36900 / 50597\n",
      "37000 / 50597\n",
      "37100 / 50597\n",
      "37200 / 50597\n",
      "37300 / 50597\n",
      "37400 / 50597\n",
      "37500 / 50597\n",
      "37600 / 50597\n",
      "37700 / 50597\n",
      "37800 / 50597\n",
      "37900 / 50597\n",
      "38000 / 50597\n",
      "38100 / 50597\n",
      "38200 / 50597\n",
      "38300 / 50597\n",
      "38400 / 50597\n",
      "38500 / 50597\n",
      "38600 / 50597\n",
      "38700 / 50597\n",
      "38800 / 50597\n",
      "38900 / 50597\n",
      "39000 / 50597\n",
      "39100 / 50597\n",
      "39200 / 50597\n",
      "39300 / 50597\n",
      "39400 / 50597\n",
      "39500 / 50597\n",
      "39600 / 50597\n",
      "39700 / 50597\n",
      "39800 / 50597\n",
      "39900 / 50597\n",
      "40000 / 50597\n",
      "40100 / 50597\n",
      "40200 / 50597\n",
      "40300 / 50597\n",
      "40400 / 50597\n",
      "40500 / 50597\n",
      "40600 / 50597\n",
      "40700 / 50597\n",
      "40800 / 50597\n",
      "40900 / 50597\n",
      "41000 / 50597\n",
      "41100 / 50597\n",
      "41200 / 50597\n",
      "41300 / 50597\n",
      "41400 / 50597\n",
      "41500 / 50597\n",
      "41600 / 50597\n",
      "41700 / 50597\n",
      "41800 / 50597\n",
      "41900 / 50597\n",
      "42000 / 50597\n",
      "42100 / 50597\n",
      "42200 / 50597\n",
      "42300 / 50597\n",
      "42400 / 50597\n",
      "42500 / 50597\n",
      "42600 / 50597\n",
      "42700 / 50597\n",
      "42800 / 50597\n",
      "42900 / 50597\n",
      "43000 / 50597\n",
      "43100 / 50597\n",
      "43200 / 50597\n",
      "43300 / 50597\n",
      "43400 / 50597\n",
      "43500 / 50597\n",
      "43600 / 50597\n",
      "43700 / 50597\n",
      "43800 / 50597\n",
      "43900 / 50597\n",
      "44000 / 50597\n",
      "44100 / 50597\n",
      "44200 / 50597\n",
      "44300 / 50597\n",
      "44400 / 50597\n",
      "44500 / 50597\n",
      "44600 / 50597\n",
      "44700 / 50597\n",
      "44800 / 50597\n",
      "44900 / 50597\n",
      "45000 / 50597\n",
      "45100 / 50597\n",
      "45200 / 50597\n",
      "45300 / 50597\n",
      "45400 / 50597\n",
      "45500 / 50597\n",
      "45600 / 50597\n",
      "45700 / 50597\n",
      "45800 / 50597\n",
      "45900 / 50597\n",
      "46000 / 50597\n",
      "46100 / 50597\n",
      "46200 / 50597\n",
      "46300 / 50597\n",
      "46400 / 50597\n",
      "46500 / 50597\n",
      "46600 / 50597\n",
      "46700 / 50597\n",
      "46800 / 50597\n",
      "46900 / 50597\n",
      "47000 / 50597\n",
      "47100 / 50597\n",
      "47200 / 50597\n",
      "47300 / 50597\n",
      "47400 / 50597\n",
      "47500 / 50597\n",
      "47600 / 50597\n",
      "47700 / 50597\n",
      "47800 / 50597\n",
      "47900 / 50597\n",
      "48000 / 50597\n",
      "48100 / 50597\n",
      "48200 / 50597\n",
      "48300 / 50597\n",
      "48400 / 50597\n",
      "48500 / 50597\n",
      "48600 / 50597\n",
      "48700 / 50597\n",
      "48800 / 50597\n",
      "48900 / 50597\n",
      "49000 / 50597\n",
      "49100 / 50597\n",
      "49200 / 50597\n",
      "49300 / 50597\n",
      "49400 / 50597\n",
      "49500 / 50597\n",
      "49600 / 50597\n",
      "49700 / 50597\n",
      "49800 / 50597\n",
      "49900 / 50597\n",
      "50000 / 50597\n",
      "50100 / 50597\n",
      "50200 / 50597\n",
      "50300 / 50597\n",
      "50400 / 50597\n",
      "50500 / 50597\n"
     ]
    }
   ],
   "source": [
    "mi_word = []\n",
    "for i in range(1, N):\n",
    "    px = (word_label[:, 0] == i).mean()\n",
    "    \n",
    "    mi = 0\n",
    "    for y in [0, 1]:\n",
    "        pxy = (word_label[x[y], 0] == i).mean()\n",
    "        mi += (pxy * py[y]) * np.log(1e-8 + pxy / px)\n",
    "        \n",
    "    mi_word.append([mi, i])\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i, '/', N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('C:/Users/moon/Desktop/5.자연어처리(실습파일)/saved_data/mi_word.pickle', 'rb') as f:\n",
    "    mi_word = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad', 'fun', 'wast', 'great', 'camera', 'think', 'movi', 'poor', 'featur', 'although', 'evil', 'recommend', 'impress', 'may', 'new', 'littl', 'portray', 'exist', 'kill', 'stori']\n"
     ]
    }
   ],
   "source": [
    "# mi_word 리스트를 내림차순으로 정렬한다.\n",
    "mi_word.sort(reverse = True)\n",
    "\n",
    "# MI 상위 20개 단어를 확인해 본다. Pelaez의 문서 내용과 일치하는지 확인한다.\n",
    "print([idx2word[y] for x, y in mi_word[:20]])\n",
    "\n",
    "# MI 상위 50% 단어로 vocabulrary를 생성한다.\n",
    "n = int(len(mi_word) * 0.5)\n",
    "word2idx2 = {idx2word[y]:(i+1) for i, [x, y] in enumerate(mi_word[:n])}\n",
    "idx2word2 = {v:k for k, v in word2idx.items()}\n",
    "\n",
    "# MI 기반 vocabulary를 이용하여 리뷰 데이터를 다시 만든다. OOV는 제거한다.\n",
    "new_review = []\n",
    "for review in reviews:\n",
    "    r = []\n",
    "    for w in review.split():\n",
    "        if w in word2idx2: # OOV 제거\n",
    "            r.append(w)\n",
    "    new_review.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movi', 'film', 'one', 'like', 'time', 'good', 'make', 'charact', 'get', 'see', 'watch', 'stori', 'even', 'would', 'realli', 'well', 'scene', 'look', 'show', 'much']\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dataset/3.400features.doc2vec'\n",
    "moedl_saved = True\n",
    "EMB_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-db9ea44648b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEMB_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1065\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             **kwargs)\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0;32m    551\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    486\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0;32m    487\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# blocks if workers too slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# a thread reporting that it finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews)]\n",
    "model = Doc2Vec(vector_size = EMB_SIZE, alpth=0.005, min_alpha = 0.0001, min_count = 1, workers=4, dm=1)\n",
    "model.build_vocab(documents)\n",
    "model.train(documents, total_examples = len(reviews), epochs = 500)\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvdm = np.array([model.docvecs[i] for i in range(len(reviews))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for review in reviews:\n",
    "    sentences.append(' '.join(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 1, analyzer = 'word', sublinear_tf = True, ngram_range=(1,1), max_features=EMB_SIZE)\n",
    "tfidf = vectorizer.fit_trainsform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, x2_train, x2_test, y_train, y_test = \\\n",
    "    train_test_split(pvdm, tfidf, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
